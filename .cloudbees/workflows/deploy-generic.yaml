napiVersion: automation.cloudbees.io/v1alpha1
kind: workflow
name: Shared Deploy Template for SquidStack Components

on:
  workflow_call:
    inputs:
    
      
      environment_name:         { type: string, required: true }
      component_name:           { type: string, required: true }
      docker_repo:              { type: string, required: true }  
    
      uses_postgres:            { type: string, required: false, default: "false" }
      uses_liquibase:           { type: string, required: false, default: "false" }
      
      
     
      artifact_id:              { type: string, required: true }
      version:                  { type: string, required: true }
      commit_sha:               { type: string, required: true }

    
      
     

    secrets:
      kubeconfig_secret:        { required: true }
      db_password:              { required: true }
      jwt_secret:               { type: string, required: false, default: "foo" } 

jobs:
   deployPreProd:
    environment: ${{ inputs.environment_name }}
  
     
    steps:
      - name: Checkout
        uses: cloudbees-io/checkout@v1

      - name: Set kubeconfig
        uses: guru-actions/kubeconfig@1.12
        with:
          secname: ${{ secrets.kubeconfig_secret }}
      
      - name: Fetch Helm dependencies
        uses: docker://alpine/helm:3.14.0
        shell: sh
        run: |
          set -eu
          helm repo add bitnami https://charts.bitnami.com/bitnami
          helm dependency build "${CLOUDBEES_WORKSPACE}/chart/${{ inputs.component_name }}"

      - name: Helm template (debug merged values)
        if: always()
        continue-on-error: true
        uses: docker://alpine/helm:3.14.0
        shell: sh
        env:
          CHART_DIR: ${{ cloudbees.workspace }}/chart/${{ inputs.component_name }}
          NAMESPACE: ${{ inputs.environment_name }}
        run: |
          set -eu
          cat > /tmp/debug-values.yaml <<'YAML'
          # keep it minimal; avoid creating JWT secret in debug
          security:
            createSecret: false
          liquibase:
            image: liquibase/liquibase:4.27
          YAML

          echo "=== helm template ==="
          helm template dbg "$CHART_DIR" \
            --namespace "$NAMESPACE" \
            -f /tmp/debug-values.yaml \
            --debug | sed -n '1,200p'


      - name: Install helm chart
        kind: deploy
        uses: cloudbees-io/helm-install@v1
        with:
          chart-location: ${{ cloudbees.workspace }}/chart/${{ inputs.component_name }}
          release-name: ${{ env.APP_NAME }}
          namespace: ${{ inputs.environment_name }}
          values: |
            image:
              repository: ${{ inputs.docker_repo }}
              tag: ${{ inputs.version }}
              pullPolicy: Always
            replicaCount: 1
            resources:
              requests: { cpu: 50m, memory: 64Mi }
              limits:   { cpu: 250m, memory: 256Mi }
            env:
              - name: FEATURE_ADMIN_HEALTH
                value: "true"
            security:
              createSecret: true
              secretName: ${{ inputs.component_name }}-secrets
              jwtSecret: ${{ secrets.JWT_SECRET }}
            # use bundled DB
            useExternalDb: false

            postgresql:
              enabled: ${{ inputs.uses_postgres == 'true' }}
              fullnameOverride: ${{ inputs.component_name }}-postgresql   # stable DNS you can reference
              auth:
                username: squid
                password: ${{ secrets.db_password }}   # set in Unify Secrets
                database: squid_auth
              networkPolicy:
                enabled: false
              primary:
                networkPolicy:
                  enabled: false
              readReplicas:
                networkPolicy:
                  enabled: false
           
            liquibase:
              image: liquibase/liquibase:4.27
              changelogFile: changelog-root.xml

      - name: Collect Liquibase evidence
        if: ${{ inputs.uses_liquibase == 'true' }}
        id: lb
        uses: docker://bitnami/kubectl:1.30
        shell: sh
        env:
          NS: ${{ inputs.environment_name }}
          RELEASE: ${{ env.APP_NAME }}
        run: |
          set -eu
          JOB_NAME="${{ env.APP_NAME }}-lb-evidence-$(date +%s)"

          cat <<'YAML' | sed "s/{{JOB_NAME}}/${JOB_NAME}/g" | kubectl apply -n "${NS}" -f -
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: {{JOB_NAME}}
            labels:
              app.kubernetes.io/name: ${{ inputs.component_name }}
              app.kubernetes.io/instance: ${{ inputs.component_name }}
              app.kubernetes.io/component: liquibase-evidence
          spec:
            backoffLimit: 0
            template:
              spec:
                restartPolicy: Never
                # Wait for DB first (same pattern as hook job)
                initContainers:
                - name: wait-for-db
                  image: busybox:1.36
                  imagePullPolicy: IfNotPresent
                  env:
                    - name: DB_HOST
                      valueFrom: { secretKeyRef: { name: ${{ inputs.component_name }}-db, key: AUTH_DB_HOST } }
                    - name: DB_PORT
                      valueFrom: { secretKeyRef: { name: ${{ inputs.component_name }}-db, key: AUTH_DB_PORT } }
                  command: ["/bin/sh","-lc"]
                  args:
                    - |
                      set -eu
                      echo "Waiting for DB at ${DB_HOST}:${DB_PORT} ..."
                      i=0
                      until nc -z -w1 "${DB_HOST}" "${DB_PORT}"; do
                        i=$((i+1))
                        if [ "$i" -ge 120 ]; then
                          echo "DB not reachable after ~2min, failing."
                          exit 1
                        fi
                        echo "still waiting..."
                        sleep 1
                      done
                      echo "DB is reachable."
                containers:
                  - name: liquibase
                    image: liquibase/liquibase:4.27
                    imagePullPolicy: IfNotPresent
                    workingDir: /liquibase/changelog
                    env:
                      - name: LIQUIBASE_URL
                        valueFrom: { secretKeyRef: { name: ${{ inputs.component_name }}-db, key: AUTH_DB_URL } }
                      - name: LIQUIBASE_USERNAME
                        valueFrom: { secretKeyRef: { name: ${{ inputs.component_name }}-db, key: AUTH_DB_USER } }
                      - name: LIQUIBASE_PASSWORD
                        valueFrom: { secretKeyRef: { name: ${{ inputs.component_name }}-db, key: AUTH_DB_PASSWORD } }
                    command: ["/bin/sh","-lc"]
                    args:
                      - |
                        set -e
                        echo "== Liquibase history =="
                        liquibase --changelog-file=changelog-root.xml \
                                  --url="${LIQUIBASE_URL}" \
                                  --username="${LIQUIBASE_USERNAME}" \
                                  --password="${LIQUIBASE_PASSWORD}" \
                                  history || true
                        echo
                        echo "== Liquibase status =="
                        liquibase --changelog-file=changelog-root.xml \
                                  --url="${LIQUIBASE_URL}" \
                                  --username="${LIQUIBASE_USERNAME}" \
                                  --password="${LIQUIBASE_PASSWORD}" \
                                  status || true
                    volumeMounts:
                      - name: liquibase-changelog
                        mountPath: /liquibase/changelog
                        readOnly: true
                volumes:
                  - name: liquibase-changelog
                    configMap:
                      name: ${{ inputs.component_name }}-liquibase
          YAML

          # Wait longer and on failure dump details
          if ! kubectl wait -n "${NS}" --for=condition=complete "job/${JOB_NAME}" --timeout=300s; then
            echo "Job did not complete, collecting diagnostics..." >&2
            kubectl get pods -n "${NS}" -l job-name="${JOB_NAME}" -o wide || true
            kubectl describe job -n "${NS}" "${JOB_NAME}" || true
            kubectl logs -n "${NS}" "job/${JOB_NAME}" --all-containers=true --tail=-1 || true
            kubectl get events -n "${NS}" --sort-by=.lastTimestamp | tail -n 100 || true
          fi

          OUT="$(kubectl logs -n "${NS}" "job/${JOB_NAME}" --all-containers=true --tail=-1 2>&1 || true)"

          {
            echo '```'
            printf '%s\n' "$OUT"
            echo '```'
          } > "$CLOUDBEES_OUTPUTS/EVIDENCE"

          # Best-effort cleanup
          kubectl delete -n "${NS}" job "${JOB_NAME}" --ignore-not-found
     

      - name: Publish Liquibase evidence
        if: ${{ inputs.uses_liquibase == 'true' }}
        uses: cloudbees-io/publish-evidence-item@v1
        with:
          content: |
            ## Liquibase Evidence (env: `${{ inputs.environment_name }}`)
            ${{ steps.lb.outputs.EVIDENCE }}
          format: MARKDOWN      

      - name: Register deployed artifact
        kind: deploy
        uses: cloudbees-io/register-deployed-artifact@v2
        with:
          artifact-id: ${{ inputs.artifact_id }}
          target-environment: ${{ inputs.environment_name }}
          labels: ver=${{ steps.short-ver.outputs.ver }}, sha=${{ steps.short-sha.outputs.sha12 }}, ns=${{ inputs.environment_name }}, rel=${{ inputs.component_name }}
